"# Orbis Project" 

// Orbis File Structure 

orbis/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes

â”œâ”€â”€ backend/                         # Flask AI Backend (Brain)
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ intent_router.py
â”‚   â”œâ”€â”€ chat_routes.py
â”‚   â”œâ”€â”€ camera.py
â”‚   â”œâ”€â”€ photo.py
â”‚   â”œâ”€â”€ photo_routes.py
â”‚   â”œâ”€â”€ outfit_images.py
â”‚   â”œâ”€â”€ qr_routes.py
â”‚   â”œâ”€â”€ weather_routes.py
â”‚   â”œâ”€â”€ cleanup_photos.py
â”‚   â”œâ”€â”€ test_camera.py
â”‚   â”œâ”€â”€ test_output.jpg
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”‚   â”œâ”€â”€ captures/                   # Runtime camera photos (ignored)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ photos.py
â”‚   â”‚   â”œâ”€â”€ vision.py
â”‚   â”‚   â””â”€â”€ debug/
â”‚   â””â”€â”€ venv/                       # Python virtual env (ignored)

â”œâ”€â”€ frontend/                        # Smart Mirror UI (React + Electron)
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ bun.lockb
â”‚   â”œâ”€â”€ components.json
â”‚   â”œâ”€â”€ eslint.config.js
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ tsconfig.app.json
â”‚   â”œâ”€â”€ tsconfig.node.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ README.md
â”‚
â”‚   â”œâ”€â”€ electron/
â”‚   â”‚   â””â”€â”€ app-shell/
â”‚   â”‚       â”œâ”€â”€ main.js
â”‚   â”‚       â”œâ”€â”€ preload.js
â”‚   â”‚       â”œâ”€â”€ package.json
â”‚   â”‚       â””â”€â”€ package-lock.json
â”‚
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.tsx
â”‚       â”œâ”€â”€ App.css
â”‚       â”œâ”€â”€ index.css
â”‚       â”œâ”€â”€ main.tsx
â”‚       â”œâ”€â”€ vite-env.d.ts
â”‚       â”‚
â”‚       â”œâ”€â”€ voice/
â”‚       â”‚   â”œâ”€â”€ actions/
â”‚       â”‚   â”‚   â”œâ”€â”€ handlePhoto.ts
â”‚       â”‚   â”‚   â””â”€â”€ handleQR.ts
â”‚       â”‚   â”œâ”€â”€ useHybridVoiceEngine.ts
â”‚       â”‚   â”œâ”€â”€ useVoice.ts
â”‚       â”‚   â”œâ”€â”€ useVoiceSocket.ts
â”‚       â”‚   â””â”€â”€ wakeWord.ts
â”‚       â”‚
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ mirror/
â”‚       â”‚   â”‚   â”œâ”€â”€ MusicPlayer.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ TimeDisplay.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ WeatherWidget.tsx
â”‚       â”‚   â”‚   â””â”€â”€ CalendarWidget.tsx
â”‚       â”‚   â””â”€â”€ ui/
â”‚       â”‚
â”‚       â”œâ”€â”€ pages/
â”‚       â”œâ”€â”€ hooks/
â”‚       â”œâ”€â”€ assets/
â”‚       â””â”€â”€ utils/

â”œâ”€â”€ voice/
â”‚   â””â”€â”€ lumiVoice/                  # Offline Voice AI Engine
â”‚       â”œâ”€â”€ .env
â”‚       â”œâ”€â”€ voice_engine.py
â”‚       â”œâ”€â”€ test_whisper.py
â”‚       â”œâ”€â”€ test.wav
â”‚       â”œâ”€â”€ test.wav.json
â”‚       â”œâ”€â”€ cmd.wav
â”‚       â”œâ”€â”€ LICENSE.txt
â”‚       â”œâ”€â”€ vfcompat.dll
â”‚       â”œâ”€â”€ appverifUI.dll
â”‚       â”‚
â”‚       â”œâ”€â”€ keywords/
â”‚       â”‚   â””â”€â”€ Hey-Lumi_en_windows_v3_0_0.ppn
â”‚       â”‚
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ ggml-tiny.en.bin
â”‚       â”‚   â””â”€â”€ porcupine_params.pv
â”‚       â”‚
â”‚       â””â”€â”€ whisper/
â”‚           â”œâ”€â”€ main.exe
â”‚           â”œâ”€â”€ server.exe
â”‚           â”œâ”€â”€ stream.exe
â”‚           â”œâ”€â”€ whisper.dll
â”‚           â””â”€â”€ Release/
â”‚               â”œâ”€â”€ whisper-cli.exe
â”‚               â”œâ”€â”€ whisper-server.exe
â”‚               â”œâ”€â”€ ggml.dll
â”‚               â””â”€â”€ libopenblas.dll

â”œâ”€â”€ vision/                         # Reserved for future CV experiments


## ğŸš€ Setup Instructions
Prerequisites

Before installation, make sure you have:

Python 3.10+ installed

Node.js 18+ and npm installed

OpenAI API key (for chat + vision)

Microphone + Camera (for voice + mirror UI)

(Optional) Electron for desktop mirror mode

ğŸ§  Backend Setup (Flask AI Brain)
1. Navigate to backend directory
cd backend

2. Create a virtual environment
python -m venv venv

3. Activate the environment

Windows

venv\Scripts\activate

1. Install dependencies
pip install -r requirements.txt

1. Create .env file

Inside backend/.env, add:

OPENAI_API_KEY=your_openai_api_key_here
WEATHER_API_KEY=your_weather_key_here

(Add anything else your backend uses.)
6. Run the backend server
python app.py


Backend will run at:

http://localhost:5001

ğŸ–¥ï¸ Frontend Setup (React + Vite Smart Mirror UI)
1. Navigate to frontend directory
cd frontend

2. Install dependencies
npm install

3. Run development server
npm run dev


Frontend runs at:

http://localhost:5173

4. Build for production
npm run build

ğŸ–¥ï¸ Electron App Setup (Desktop Mirror Mode)

Inside frontend:

cd frontend/electron/app-shell
npm install
npm start


This launches a frameless desktop app designed to run on a wall-mounted smart mirror.

ğŸ¤ Lumi Voice Engine Setup (Offline Wake Word + Whisper)
1. Navigate to LumiVoice engine
cd voice/lumiVoice

2. Install dependencies
pip install -r requirements.txt   # if you create one


(Your folder includes binaries + Python scripts.)

3. Add .env file

Inside voice/lumiVoice/.env:

PICOVOICE_ACCESS_KEY=your_api_key_here

4. Run the voice engine
python voice_engine.py


This enables:

â€œHey Lumiâ€ wake word (Porcupine)

Whisper STT (offline)

Real-time voice commands

Communication with frontend via socket

ğŸ“± How to Use Orbis
1. Start all systems:

Backend â†’ http://localhost:5000

Frontend â†’ http://localhost:5173

Electron app (optional)

LumiVoice engine (optional but recommended)

2. Open the frontend in a browser or Electron
3. Allow camera + microphone permissions
4. Speak voice commands or use UI buttons

Examples:

â€œLumi, play musicâ€

â€œLumi, show me todayâ€™s weatherâ€

â€œLumi, take my photoâ€

â€œLumi, what outfit should I wear?â€

5. Mirror UI updates in real time
ğŸ”’ Safety & Privacy

Orbis always follows safety rules:

Safe: clothing, outfit details, colors, style

Never: gender, race, age, attractiveness

Local processing: wake word + STT run offline in LumiVoice

Your camera images stay on device unless you choose to save them

ğŸŒ Deploying Orbis on a Smart Mirror Device
1. Deploy backend on a server or local Raspberry Pi

Update frontend .env:

VITE_BACKEND_URL=http://your-server-ip:5000

2. Build frontend
npm run build

3. Serve dist/ folder using any static server:
cd frontend/dist
python -m http.server 8080

4. Open the mirror UI via the mirrorâ€™s browser or fullscreen Electron
ğŸ› ï¸ Troubleshooting
âŒ Camera not working

Ensure permissions granted

Check another app isnâ€™t using the camera

âŒ Voice not working

Microphone permissions not granted

Whisper DLLs missing (Windows)

Wake word engine not running

âŒ Frontend can't reach backend

Check backend running on port 5000

Fix CORS in backend if needed

Update VITE_BACKEND_URL

âŒ Electron crashes

Delete node_modules inside app-shell and reinstall

ğŸ“¦ Technologies Used
Backend

Flask

Python CV tools

OpenAI GPT APIs

Socket.IO

Frontend

React 19

TypeScript

Vite

Tailwind CSS

Socket.IO Client

Voice Engine

Porcupine (wake word)

Whisper (offline STT)

Python audio stack